{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNuB+x/QEdJA9YSxdhPGsrE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dusein/MachineLearningTask/blob/main/12thWeekTask/CNN_For_Fashion_Mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lhx7rK8ZZj7r"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the CNN architecture\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, kernel_size=3, pooling_type='max'):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.kernel_size = kernel_size\n",
        "        self.pooling_type = pooling_type\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=self.kernel_size, padding=self.kernel_size // 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=self.kernel_size, padding=self.kernel_size // 2)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=self.kernel_size, padding=self.kernel_size // 2)\n",
        "\n",
        "        if self.pooling_type == 'max':\n",
        "            self.pool = nn.MaxPool2d(2, 2)\n",
        "        elif self.pooling_type == 'avg':\n",
        "            self.pool = nn.AvgPool2d(2, 2)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 3 * 3, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = x.view(-1, 128 * 3 * 3)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess FashionMNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFjG-kiGZnr6",
        "outputId": "ae9dc840-f927-4785-ff57-840e73d952f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 11.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 201kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.78MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 6.84MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Early Stopping Callback\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, delta=0):\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "        elif val_loss > self.best_loss - self.delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0"
      ],
      "metadata": {
        "id": "OgwqChE6ZoJi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate function\n",
        "def train_and_evaluate(kernel_size, pooling_type, optimizer_type, epochs):\n",
        "    model = CNN(kernel_size=kernel_size, pooling_type=pooling_type).to(device)\n",
        "\n",
        "    # Define optimizer\n",
        "    if optimizer_type == 'SGD':\n",
        "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "    elif optimizer_type == 'RMSProp':\n",
        "        optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
        "    elif optimizer_type == 'Adam':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
        "    early_stopping = EarlyStopping(patience=10)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_accuracy = 100 * correct / total\n",
        "        scheduler.step(val_loss)\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {running_loss/len(train_loader):.4f}, Validation Loss: {val_loss/len(test_loader):.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "        if early_stopping(val_loss):\n",
        "            print(\"Early stopping triggered\")\n",
        "            break"
      ],
      "metadata": {
        "id": "6210r0_5ZqKu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters to compare\n",
        "kernel_sizes = [3, 5, 7]\n",
        "pooling_types = ['max', 'avg']\n",
        "optimizers = ['SGD', 'RMSProp', 'Adam']\n",
        "epochs_list = [5]\n",
        "# epochs_list = [5, 50, 100, 250, 350]\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Iterate through configurations\n",
        "for kernel_size in kernel_sizes:\n",
        "    for pooling_type in pooling_types:\n",
        "        for optimizer_type in optimizers:\n",
        "            for epochs in epochs_list:\n",
        "                print(f\"\\nConfiguration: Kernel={kernel_size}, Pooling={pooling_type}, Optimizer={optimizer_type}, Epochs={epochs}\")\n",
        "                train_and_evaluate(kernel_size, pooling_type, optimizer_type, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wz4FjGb7Zrpk",
        "outputId": "36773ec6-c25d-4fdd-8fd8-06bd0dfe9908"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Configuration: Kernel=3, Pooling=max, Optimizer=SGD, Epochs=5\n",
            "Epoch 1/5, Training Loss: 0.9822, Validation Loss: 0.5351, Test Accuracy: 79.58%\n",
            "Epoch 2/5, Training Loss: 0.4893, Validation Loss: 0.4090, Test Accuracy: 84.71%\n",
            "Epoch 3/5, Training Loss: 0.4069, Validation Loss: 0.3584, Test Accuracy: 86.56%\n",
            "Epoch 4/5, Training Loss: 0.3615, Validation Loss: 0.3445, Test Accuracy: 86.91%\n",
            "Epoch 5/5, Training Loss: 0.3356, Validation Loss: 0.3156, Test Accuracy: 88.18%\n",
            "\n",
            "Configuration: Kernel=3, Pooling=max, Optimizer=RMSProp, Epochs=5\n",
            "Epoch 1/5, Training Loss: 0.6277, Validation Loss: 0.3863, Test Accuracy: 85.57%\n",
            "Epoch 2/5, Training Loss: 0.3708, Validation Loss: 0.3327, Test Accuracy: 87.62%\n",
            "Epoch 3/5, Training Loss: 0.3148, Validation Loss: 0.2905, Test Accuracy: 88.97%\n",
            "Epoch 4/5, Training Loss: 0.2803, Validation Loss: 0.2719, Test Accuracy: 89.84%\n",
            "Epoch 5/5, Training Loss: 0.2581, Validation Loss: 0.2512, Test Accuracy: 90.84%\n",
            "\n",
            "Configuration: Kernel=3, Pooling=max, Optimizer=Adam, Epochs=5\n",
            "Epoch 1/5, Training Loss: 0.6378, Validation Loss: 0.4077, Test Accuracy: 84.23%\n",
            "Epoch 2/5, Training Loss: 0.3757, Validation Loss: 0.3264, Test Accuracy: 87.85%\n",
            "Epoch 3/5, Training Loss: 0.3192, Validation Loss: 0.3042, Test Accuracy: 88.95%\n",
            "Epoch 4/5, Training Loss: 0.2871, Validation Loss: 0.2768, Test Accuracy: 89.69%\n",
            "Epoch 5/5, Training Loss: 0.2652, Validation Loss: 0.2641, Test Accuracy: 90.19%\n",
            "\n",
            "Configuration: Kernel=3, Pooling=avg, Optimizer=SGD, Epochs=5\n",
            "Epoch 1/5, Training Loss: 1.1470, Validation Loss: 0.7352, Test Accuracy: 72.53%\n",
            "Epoch 2/5, Training Loss: 0.6827, Validation Loss: 0.5772, Test Accuracy: 77.54%\n",
            "Epoch 3/5, Training Loss: 0.5901, Validation Loss: 0.5356, Test Accuracy: 79.52%\n",
            "Epoch 4/5, Training Loss: 0.5395, Validation Loss: 0.4752, Test Accuracy: 82.25%\n",
            "Epoch 5/5, Training Loss: 0.4961, Validation Loss: 0.4540, Test Accuracy: 83.26%\n",
            "\n",
            "Configuration: Kernel=3, Pooling=avg, Optimizer=RMSProp, Epochs=5\n",
            "Epoch 1/5, Training Loss: 0.7398, Validation Loss: 0.4979, Test Accuracy: 80.89%\n",
            "Epoch 2/5, Training Loss: 0.4723, Validation Loss: 0.4298, Test Accuracy: 84.25%\n",
            "Epoch 3/5, Training Loss: 0.3936, Validation Loss: 0.3591, Test Accuracy: 86.62%\n",
            "Epoch 4/5, Training Loss: 0.3489, Validation Loss: 0.3374, Test Accuracy: 87.48%\n",
            "Epoch 5/5, Training Loss: 0.3208, Validation Loss: 0.3068, Test Accuracy: 88.62%\n",
            "\n",
            "Configuration: Kernel=3, Pooling=avg, Optimizer=Adam, Epochs=5\n",
            "Epoch 1/5, Training Loss: 0.7512, Validation Loss: 0.5155, Test Accuracy: 80.27%\n",
            "Epoch 2/5, Training Loss: 0.4898, Validation Loss: 0.4228, Test Accuracy: 83.96%\n",
            "Epoch 3/5, Training Loss: 0.4156, Validation Loss: 0.3684, Test Accuracy: 86.04%\n",
            "Epoch 4/5, Training Loss: 0.3660, Validation Loss: 0.3496, Test Accuracy: 87.03%\n",
            "Epoch 5/5, Training Loss: 0.3350, Validation Loss: 0.3223, Test Accuracy: 88.11%\n",
            "\n",
            "Configuration: Kernel=5, Pooling=max, Optimizer=SGD, Epochs=5\n",
            "Epoch 1/5, Training Loss: 0.8625, Validation Loss: 0.5052, Test Accuracy: 80.79%\n",
            "Epoch 2/5, Training Loss: 0.4650, Validation Loss: 0.3916, Test Accuracy: 85.45%\n",
            "Epoch 3/5, Training Loss: 0.3886, Validation Loss: 0.3862, Test Accuracy: 85.56%\n",
            "Epoch 4/5, Training Loss: 0.3459, Validation Loss: 0.3436, Test Accuracy: 87.56%\n",
            "Epoch 5/5, Training Loss: 0.3163, Validation Loss: 0.3087, Test Accuracy: 88.69%\n",
            "\n",
            "Configuration: Kernel=5, Pooling=max, Optimizer=RMSProp, Epochs=5\n",
            "Epoch 1/5, Training Loss: 0.6859, Validation Loss: 0.3977, Test Accuracy: 85.05%\n",
            "Epoch 2/5, Training Loss: 0.3691, Validation Loss: 0.3269, Test Accuracy: 87.81%\n",
            "Epoch 3/5, Training Loss: 0.3092, Validation Loss: 0.2956, Test Accuracy: 88.94%\n",
            "Epoch 4/5, Training Loss: 0.2728, Validation Loss: 0.2661, Test Accuracy: 90.03%\n",
            "Epoch 5/5, Training Loss: 0.2483, Validation Loss: 0.2703, Test Accuracy: 90.13%\n",
            "\n",
            "Configuration: Kernel=5, Pooling=max, Optimizer=Adam, Epochs=5\n",
            "Epoch 1/5, Training Loss: 0.5824, Validation Loss: 0.3723, Test Accuracy: 86.23%\n",
            "Epoch 2/5, Training Loss: 0.3512, Validation Loss: 0.3346, Test Accuracy: 87.39%\n",
            "Epoch 3/5, Training Loss: 0.2953, Validation Loss: 0.2901, Test Accuracy: 89.53%\n",
            "Epoch 4/5, Training Loss: 0.2630, Validation Loss: 0.2737, Test Accuracy: 89.92%\n",
            "Epoch 5/5, Training Loss: 0.2362, Validation Loss: 0.2606, Test Accuracy: 90.47%\n",
            "\n",
            "Configuration: Kernel=5, Pooling=avg, Optimizer=SGD, Epochs=5\n",
            "Epoch 1/5, Training Loss: 1.0669, Validation Loss: 0.6514, Test Accuracy: 74.25%\n",
            "Epoch 2/5, Training Loss: 0.6024, Validation Loss: 0.5264, Test Accuracy: 80.20%\n",
            "Epoch 3/5, Training Loss: 0.5192, Validation Loss: 0.4753, Test Accuracy: 81.76%\n",
            "Epoch 4/5, Training Loss: 0.4632, Validation Loss: 0.4276, Test Accuracy: 83.90%\n",
            "Epoch 5/5, Training Loss: 0.4263, Validation Loss: 0.4045, Test Accuracy: 85.09%\n",
            "\n",
            "Configuration: Kernel=5, Pooling=avg, Optimizer=RMSProp, Epochs=5\n",
            "Epoch 1/5, Training Loss: 0.7229, Validation Loss: 0.4954, Test Accuracy: 80.72%\n",
            "Epoch 2/5, Training Loss: 0.4374, Validation Loss: 0.3689, Test Accuracy: 86.18%\n",
            "Epoch 3/5, Training Loss: 0.3612, Validation Loss: 0.3288, Test Accuracy: 87.81%\n",
            "Epoch 4/5, Training Loss: 0.3190, Validation Loss: 0.3070, Test Accuracy: 88.73%\n",
            "Epoch 5/5, Training Loss: 0.2909, Validation Loss: 0.2837, Test Accuracy: 89.44%\n",
            "\n",
            "Configuration: Kernel=5, Pooling=avg, Optimizer=Adam, Epochs=5\n",
            "Epoch 1/5, Training Loss: 0.6812, Validation Loss: 0.4639, Test Accuracy: 82.51%\n",
            "Epoch 2/5, Training Loss: 0.4342, Validation Loss: 0.3749, Test Accuracy: 85.72%\n",
            "Epoch 3/5, Training Loss: 0.3651, Validation Loss: 0.3361, Test Accuracy: 87.40%\n",
            "Epoch 4/5, Training Loss: 0.3231, Validation Loss: 0.3062, Test Accuracy: 88.42%\n",
            "Epoch 5/5, Training Loss: 0.2975, Validation Loss: 0.2882, Test Accuracy: 89.06%\n",
            "\n",
            "Configuration: Kernel=7, Pooling=max, Optimizer=SGD, Epochs=5\n",
            "Epoch 1/5, Training Loss: 0.8232, Validation Loss: 0.4842, Test Accuracy: 81.50%\n",
            "Epoch 2/5, Training Loss: 0.4536, Validation Loss: 0.3855, Test Accuracy: 85.54%\n",
            "Epoch 3/5, Training Loss: 0.3753, Validation Loss: 0.3551, Test Accuracy: 86.76%\n",
            "Epoch 4/5, Training Loss: 0.3286, Validation Loss: 0.3199, Test Accuracy: 88.05%\n",
            "Epoch 5/5, Training Loss: 0.3018, Validation Loss: 0.2908, Test Accuracy: 88.90%\n",
            "\n",
            "Configuration: Kernel=7, Pooling=max, Optimizer=RMSProp, Epochs=5\n",
            "Epoch 1/5, Training Loss: 0.7737, Validation Loss: 0.4773, Test Accuracy: 81.91%\n",
            "Epoch 2/5, Training Loss: 0.4114, Validation Loss: 0.3506, Test Accuracy: 86.85%\n",
            "Epoch 3/5, Training Loss: 0.3463, Validation Loss: 0.3182, Test Accuracy: 87.96%\n",
            "Epoch 4/5, Training Loss: 0.3085, Validation Loss: 0.2983, Test Accuracy: 88.65%\n",
            "Epoch 5/5, Training Loss: 0.2805, Validation Loss: 0.3287, Test Accuracy: 88.20%\n",
            "\n",
            "Configuration: Kernel=7, Pooling=max, Optimizer=Adam, Epochs=5\n",
            "Epoch 1/5, Training Loss: 0.5690, Validation Loss: 0.3783, Test Accuracy: 85.78%\n",
            "Epoch 2/5, Training Loss: 0.3432, Validation Loss: 0.3115, Test Accuracy: 88.55%\n",
            "Epoch 3/5, Training Loss: 0.2886, Validation Loss: 0.2952, Test Accuracy: 89.11%\n",
            "Epoch 4/5, Training Loss: 0.2595, Validation Loss: 0.2799, Test Accuracy: 89.66%\n",
            "Epoch 5/5, Training Loss: 0.2324, Validation Loss: 0.2682, Test Accuracy: 90.48%\n",
            "\n",
            "Configuration: Kernel=7, Pooling=avg, Optimizer=SGD, Epochs=5\n",
            "Epoch 1/5, Training Loss: 0.9986, Validation Loss: 0.6410, Test Accuracy: 74.92%\n",
            "Epoch 2/5, Training Loss: 0.6067, Validation Loss: 0.5428, Test Accuracy: 78.74%\n",
            "Epoch 3/5, Training Loss: 0.5258, Validation Loss: 0.4808, Test Accuracy: 81.63%\n",
            "Epoch 4/5, Training Loss: 0.4669, Validation Loss: 0.4414, Test Accuracy: 83.32%\n",
            "Epoch 5/5, Training Loss: 0.4292, Validation Loss: 0.4110, Test Accuracy: 84.55%\n",
            "\n",
            "Configuration: Kernel=7, Pooling=avg, Optimizer=RMSProp, Epochs=5\n",
            "Epoch 1/5, Training Loss: 0.8877, Validation Loss: 0.5752, Test Accuracy: 77.56%\n",
            "Epoch 2/5, Training Loss: 0.4798, Validation Loss: 0.4111, Test Accuracy: 84.71%\n",
            "Epoch 3/5, Training Loss: 0.3941, Validation Loss: 0.3545, Test Accuracy: 86.99%\n",
            "Epoch 4/5, Training Loss: 0.3407, Validation Loss: 0.3562, Test Accuracy: 87.27%\n",
            "Epoch 5/5, Training Loss: 0.3104, Validation Loss: 0.3075, Test Accuracy: 88.51%\n",
            "\n",
            "Configuration: Kernel=7, Pooling=avg, Optimizer=Adam, Epochs=5\n",
            "Epoch 1/5, Training Loss: 0.6579, Validation Loss: 0.4348, Test Accuracy: 83.95%\n",
            "Epoch 2/5, Training Loss: 0.4032, Validation Loss: 0.3559, Test Accuracy: 86.76%\n",
            "Epoch 3/5, Training Loss: 0.3429, Validation Loss: 0.3308, Test Accuracy: 87.75%\n",
            "Epoch 4/5, Training Loss: 0.3018, Validation Loss: 0.3083, Test Accuracy: 88.63%\n",
            "Epoch 5/5, Training Loss: 0.2714, Validation Loss: 0.2861, Test Accuracy: 89.71%\n"
          ]
        }
      ]
    }
  ]
}