{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dusein/MachineLearningTask/blob/main/12thWeekTask/CNN_For_Cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ftVH5cIlKHCU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the CNN architecture\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, kernel_size=3, pooling_type='max'):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.kernel_size = kernel_size\n",
        "        self.pooling_type = pooling_type\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=self.kernel_size, padding=self.kernel_size // 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=self.kernel_size, padding=self.kernel_size // 2)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=self.kernel_size, padding=self.kernel_size // 2)\n",
        "\n",
        "        if self.pooling_type == 'max':\n",
        "            self.pool = nn.MaxPool2d(2, 2)\n",
        "        elif self.pooling_type == 'avg':\n",
        "            self.pool = nn.AvgPool2d(2, 2)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = x.view(-1, 128 * 4 * 4)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZThINoCTLjgr",
        "outputId": "ef8a1762-0de0-4dc9-fc0a-44031dd7ff26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 48.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess CIFAR-10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2b4thaU4LiSM"
      },
      "outputs": [],
      "source": [
        "# Early Stopping Callback\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, delta=0):\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "        elif val_loss > self.best_loss - self.delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IrWMJTeQLd-o"
      },
      "outputs": [],
      "source": [
        "# Train and evaluate function\n",
        "def train_and_evaluate(kernel_size, pooling_type, optimizer_type, epochs):\n",
        "    model = CNN(kernel_size=kernel_size, pooling_type=pooling_type).to(device)\n",
        "\n",
        "    # Define optimizer\n",
        "    if optimizer_type == 'SGD':\n",
        "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "    elif optimizer_type == 'RMSProp':\n",
        "        optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
        "    elif optimizer_type == 'Adam':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
        "    early_stopping = EarlyStopping(patience=10)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_accuracy = 100 * correct / total\n",
        "        scheduler.step(val_loss)\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {running_loss/len(train_loader):.4f}, Validation Loss: {val_loss/len(test_loader):.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "        if early_stopping(val_loss):\n",
        "            print(\"Early stopping triggered\")\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvssnPUpLaHH",
        "outputId": "8ab66257-1998-4698-9ab7-42e87ec7da5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Configuration: Kernel=3, Pooling=max, Optimizer=SGD, Epochs=5\n",
            "Epoch 1/5, Training Loss: 2.0285, Validation Loss: 1.7005, Test Accuracy: 37.43%\n",
            "Epoch 2/5, Training Loss: 1.6173, Validation Loss: 1.4721, Test Accuracy: 46.32%\n",
            "Epoch 3/5, Training Loss: 1.4612, Validation Loss: 1.3560, Test Accuracy: 50.28%\n",
            "Epoch 4/5, Training Loss: 1.3412, Validation Loss: 1.2412, Test Accuracy: 55.06%\n",
            "Epoch 5/5, Training Loss: 1.2334, Validation Loss: 1.1171, Test Accuracy: 59.58%\n",
            "\n",
            "Configuration: Kernel=3, Pooling=max, Optimizer=RMSProp, Epochs=5\n",
            "Epoch 1/5, Training Loss: 1.8109, Validation Loss: 1.5512, Test Accuracy: 43.59%\n",
            "Epoch 2/5, Training Loss: 1.4608, Validation Loss: 1.2834, Test Accuracy: 53.27%\n",
            "Epoch 3/5, Training Loss: 1.2888, Validation Loss: 1.1899, Test Accuracy: 57.02%\n",
            "Epoch 4/5, Training Loss: 1.1629, Validation Loss: 1.1334, Test Accuracy: 59.62%\n",
            "Epoch 5/5, Training Loss: 1.0759, Validation Loss: 0.9643, Test Accuracy: 65.60%\n",
            "\n",
            "Configuration: Kernel=3, Pooling=max, Optimizer=Adam, Epochs=5\n",
            "Epoch 1/5, Training Loss: 1.7083, Validation Loss: 1.4130, Test Accuracy: 47.84%\n",
            "Epoch 2/5, Training Loss: 1.3872, Validation Loss: 1.2277, Test Accuracy: 55.19%\n",
            "Epoch 3/5, Training Loss: 1.2155, Validation Loss: 1.0985, Test Accuracy: 60.92%\n",
            "Epoch 4/5, Training Loss: 1.0962, Validation Loss: 0.9882, Test Accuracy: 65.16%\n",
            "Epoch 5/5, Training Loss: 0.9995, Validation Loss: 0.9470, Test Accuracy: 66.24%\n",
            "\n",
            "Configuration: Kernel=3, Pooling=avg, Optimizer=SGD, Epochs=5\n",
            "Epoch 1/5, Training Loss: 2.1256, Validation Loss: 1.8848, Test Accuracy: 30.20%\n",
            "Epoch 2/5, Training Loss: 1.8136, Validation Loss: 1.6948, Test Accuracy: 38.31%\n",
            "Epoch 3/5, Training Loss: 1.6645, Validation Loss: 1.5399, Test Accuracy: 42.90%\n",
            "Epoch 4/5, Training Loss: 1.5497, Validation Loss: 1.4413, Test Accuracy: 47.39%\n",
            "Epoch 5/5, Training Loss: 1.4742, Validation Loss: 1.4381, Test Accuracy: 47.70%\n",
            "\n",
            "Configuration: Kernel=3, Pooling=avg, Optimizer=RMSProp, Epochs=5\n",
            "Epoch 1/5, Training Loss: 1.7756, Validation Loss: 1.5212, Test Accuracy: 44.47%\n",
            "Epoch 2/5, Training Loss: 1.4890, Validation Loss: 1.3673, Test Accuracy: 49.74%\n",
            "Epoch 3/5, Training Loss: 1.3636, Validation Loss: 1.2364, Test Accuracy: 55.28%\n",
            "Epoch 4/5, Training Loss: 1.2545, Validation Loss: 1.1789, Test Accuracy: 57.63%\n",
            "Epoch 5/5, Training Loss: 1.1820, Validation Loss: 1.1012, Test Accuracy: 60.50%\n",
            "\n",
            "Configuration: Kernel=3, Pooling=avg, Optimizer=Adam, Epochs=5\n",
            "Epoch 1/5, Training Loss: 1.7497, Validation Loss: 1.4788, Test Accuracy: 45.24%\n",
            "Epoch 2/5, Training Loss: 1.4741, Validation Loss: 1.3318, Test Accuracy: 52.15%\n",
            "Epoch 3/5, Training Loss: 1.3455, Validation Loss: 1.2291, Test Accuracy: 55.53%\n",
            "Epoch 4/5, Training Loss: 1.2509, Validation Loss: 1.1351, Test Accuracy: 59.36%\n",
            "Epoch 5/5, Training Loss: 1.1718, Validation Loss: 1.0888, Test Accuracy: 61.25%\n",
            "\n",
            "Configuration: Kernel=5, Pooling=max, Optimizer=SGD, Epochs=5\n",
            "Epoch 1/5, Training Loss: 1.9490, Validation Loss: 1.6486, Test Accuracy: 39.65%\n",
            "Epoch 2/5, Training Loss: 1.5684, Validation Loss: 1.4356, Test Accuracy: 47.59%\n",
            "Epoch 3/5, Training Loss: 1.3817, Validation Loss: 1.2458, Test Accuracy: 54.29%\n",
            "Epoch 4/5, Training Loss: 1.2309, Validation Loss: 1.0922, Test Accuracy: 60.59%\n",
            "Epoch 5/5, Training Loss: 1.1119, Validation Loss: 1.0000, Test Accuracy: 64.10%\n",
            "\n",
            "Configuration: Kernel=5, Pooling=max, Optimizer=RMSProp, Epochs=5\n",
            "Epoch 1/5, Training Loss: 1.8634, Validation Loss: 1.5564, Test Accuracy: 42.83%\n",
            "Epoch 2/5, Training Loss: 1.4508, Validation Loss: 1.2830, Test Accuracy: 53.93%\n",
            "Epoch 3/5, Training Loss: 1.2841, Validation Loss: 1.1705, Test Accuracy: 58.00%\n",
            "Epoch 4/5, Training Loss: 1.1659, Validation Loss: 1.0574, Test Accuracy: 62.51%\n",
            "Epoch 5/5, Training Loss: 1.0793, Validation Loss: 1.2009, Test Accuracy: 58.90%\n",
            "\n",
            "Configuration: Kernel=5, Pooling=max, Optimizer=Adam, Epochs=5\n",
            "Epoch 1/5, Training Loss: 1.7083, Validation Loss: 1.4179, Test Accuracy: 47.29%\n",
            "Epoch 2/5, Training Loss: 1.3409, Validation Loss: 1.2081, Test Accuracy: 56.17%\n",
            "Epoch 3/5, Training Loss: 1.1569, Validation Loss: 1.0732, Test Accuracy: 61.99%\n",
            "Epoch 4/5, Training Loss: 1.0325, Validation Loss: 0.9153, Test Accuracy: 67.73%\n",
            "Epoch 5/5, Training Loss: 0.9395, Validation Loss: 0.9091, Test Accuracy: 67.63%\n",
            "\n",
            "Configuration: Kernel=5, Pooling=avg, Optimizer=SGD, Epochs=5\n",
            "Epoch 1/5, Training Loss: 2.0540, Validation Loss: 1.7931, Test Accuracy: 33.43%\n",
            "Epoch 2/5, Training Loss: 1.7111, Validation Loss: 1.5854, Test Accuracy: 41.52%\n",
            "Epoch 3/5, Training Loss: 1.5607, Validation Loss: 1.4610, Test Accuracy: 46.18%\n",
            "Epoch 4/5, Training Loss: 1.4575, Validation Loss: 1.3646, Test Accuracy: 50.96%\n",
            "Epoch 5/5, Training Loss: 1.3783, Validation Loss: 1.2800, Test Accuracy: 53.65%\n",
            "\n",
            "Configuration: Kernel=5, Pooling=avg, Optimizer=RMSProp, Epochs=5\n",
            "Epoch 1/5, Training Loss: 1.8931, Validation Loss: 1.6097, Test Accuracy: 41.33%\n",
            "Epoch 2/5, Training Loss: 1.5460, Validation Loss: 1.4264, Test Accuracy: 47.55%\n",
            "Epoch 3/5, Training Loss: 1.3843, Validation Loss: 1.2778, Test Accuracy: 54.24%\n",
            "Epoch 4/5, Training Loss: 1.2510, Validation Loss: 1.1647, Test Accuracy: 58.58%\n",
            "Epoch 5/5, Training Loss: 1.1477, Validation Loss: 1.0613, Test Accuracy: 62.82%\n",
            "\n",
            "Configuration: Kernel=5, Pooling=avg, Optimizer=Adam, Epochs=5\n",
            "Epoch 1/5, Training Loss: 1.7659, Validation Loss: 1.4995, Test Accuracy: 44.23%\n",
            "Epoch 2/5, Training Loss: 1.4418, Validation Loss: 1.3014, Test Accuracy: 52.27%\n",
            "Epoch 3/5, Training Loss: 1.2669, Validation Loss: 1.1642, Test Accuracy: 58.28%\n",
            "Epoch 4/5, Training Loss: 1.1328, Validation Loss: 1.0383, Test Accuracy: 62.57%\n",
            "Epoch 5/5, Training Loss: 1.0354, Validation Loss: 0.9730, Test Accuracy: 65.85%\n",
            "\n",
            "Configuration: Kernel=7, Pooling=max, Optimizer=SGD, Epochs=5\n",
            "Epoch 1/5, Training Loss: 1.9378, Validation Loss: 1.6094, Test Accuracy: 39.20%\n",
            "Epoch 2/5, Training Loss: 1.5396, Validation Loss: 1.3850, Test Accuracy: 49.88%\n",
            "Epoch 3/5, Training Loss: 1.3319, Validation Loss: 1.2089, Test Accuracy: 56.53%\n",
            "Epoch 4/5, Training Loss: 1.1845, Validation Loss: 1.0929, Test Accuracy: 61.12%\n",
            "Epoch 5/5, Training Loss: 1.0699, Validation Loss: 1.0452, Test Accuracy: 64.07%\n",
            "\n",
            "Configuration: Kernel=7, Pooling=max, Optimizer=RMSProp, Epochs=5\n",
            "Epoch 1/5, Training Loss: 2.1174, Validation Loss: 1.8121, Test Accuracy: 34.18%\n",
            "Epoch 2/5, Training Loss: 1.6401, Validation Loss: 1.5766, Test Accuracy: 42.80%\n",
            "Epoch 3/5, Training Loss: 1.4730, Validation Loss: 1.3877, Test Accuracy: 49.80%\n",
            "Epoch 4/5, Training Loss: 1.3431, Validation Loss: 1.2733, Test Accuracy: 53.84%\n",
            "Epoch 5/5, Training Loss: 1.2482, Validation Loss: 1.1611, Test Accuracy: 58.58%\n",
            "\n",
            "Configuration: Kernel=7, Pooling=max, Optimizer=Adam, Epochs=5\n",
            "Epoch 1/5, Training Loss: 1.7279, Validation Loss: 1.4358, Test Accuracy: 46.95%\n",
            "Epoch 2/5, Training Loss: 1.3795, Validation Loss: 1.2761, Test Accuracy: 54.25%\n",
            "Epoch 3/5, Training Loss: 1.2148, Validation Loss: 1.0880, Test Accuracy: 60.89%\n",
            "Epoch 4/5, Training Loss: 1.1013, Validation Loss: 1.0040, Test Accuracy: 64.53%\n",
            "Epoch 5/5, Training Loss: 1.0180, Validation Loss: 0.9505, Test Accuracy: 66.61%\n",
            "\n",
            "Configuration: Kernel=7, Pooling=avg, Optimizer=SGD, Epochs=5\n",
            "Epoch 1/5, Training Loss: 2.0144, Validation Loss: 1.7434, Test Accuracy: 35.51%\n",
            "Epoch 2/5, Training Loss: 1.6833, Validation Loss: 1.5543, Test Accuracy: 43.14%\n",
            "Epoch 3/5, Training Loss: 1.5432, Validation Loss: 1.4293, Test Accuracy: 47.61%\n",
            "Epoch 4/5, Training Loss: 1.4432, Validation Loss: 1.3152, Test Accuracy: 51.75%\n",
            "Epoch 5/5, Training Loss: 1.3422, Validation Loss: 1.2489, Test Accuracy: 54.83%\n",
            "\n",
            "Configuration: Kernel=7, Pooling=avg, Optimizer=RMSProp, Epochs=5\n",
            "Epoch 1/5, Training Loss: 2.0364, Validation Loss: 1.7160, Test Accuracy: 36.73%\n",
            "Epoch 2/5, Training Loss: 1.6447, Validation Loss: 1.4943, Test Accuracy: 45.79%\n",
            "Epoch 3/5, Training Loss: 1.4732, Validation Loss: 1.4361, Test Accuracy: 48.26%\n",
            "Epoch 4/5, Training Loss: 1.3671, Validation Loss: 1.2602, Test Accuracy: 54.44%\n",
            "Epoch 5/5, Training Loss: 1.2677, Validation Loss: 1.2227, Test Accuracy: 56.60%\n",
            "\n",
            "Configuration: Kernel=7, Pooling=avg, Optimizer=Adam, Epochs=5\n",
            "Epoch 1/5, Training Loss: 1.7999, Validation Loss: 1.5752, Test Accuracy: 42.57%\n",
            "Epoch 2/5, Training Loss: 1.5190, Validation Loss: 1.4265, Test Accuracy: 48.77%\n",
            "Epoch 3/5, Training Loss: 1.3776, Validation Loss: 1.2689, Test Accuracy: 54.21%\n",
            "Epoch 4/5, Training Loss: 1.2689, Validation Loss: 1.1887, Test Accuracy: 57.32%\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters to compare\n",
        "kernel_sizes = [3, 5, 7]\n",
        "pooling_types = ['max', 'avg']\n",
        "optimizers = ['SGD', 'RMSProp', 'Adam']\n",
        "epochs_list = [5]\n",
        "# epochs_list = [5, 50, 100, 250, 350]\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Iterate through configurations\n",
        "for kernel_size in kernel_sizes:\n",
        "    for pooling_type in pooling_types:\n",
        "        for optimizer_type in optimizers:\n",
        "            for epochs in epochs_list:\n",
        "                print(f\"\\nConfiguration: Kernel={kernel_size}, Pooling={pooling_type}, Optimizer={optimizer_type}, Epochs={epochs}\")\n",
        "                train_and_evaluate(kernel_size, pooling_type, optimizer_type, epochs)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMBeS02Rd7l49AVynaiuRWw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}