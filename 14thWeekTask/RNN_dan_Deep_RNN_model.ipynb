{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPInSbb6MByD6WEjfNw9Kib",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dusein/MachineLearningTask/blob/main/14thWeekTask/RNN_dan_Deep_RNN_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "Z3uf7DbBWFvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGYk1rThTyXf",
        "outputId": "9dcbb7a9-6dfb-4085-9ef2-ed1e48743d8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ganti 'your_file_path' dengan path sebenarnya ke file CSV Anda di Google Drive\n",
        "file_path = '/content/drive/My Drive/Dataset/diabetes_012_health_indicators_BRFSS2015.csv'\n",
        "\n",
        "# Membaca file CSV ke dalam DataFrame\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Menampilkan beberapa baris pertama dari DataFrame\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UH6SUO0uWCLp",
        "outputId": "00362419-a1e2-4a03-9a5c-8b515c856848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Diabetes_012  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
            "0           0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
            "1           0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
            "2           0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
            "3           0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
            "4           0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
            "\n",
            "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
            "0                   0.0           0.0     0.0  ...            1.0   \n",
            "1                   0.0           1.0     0.0  ...            0.0   \n",
            "2                   0.0           0.0     1.0  ...            1.0   \n",
            "3                   0.0           1.0     1.0  ...            1.0   \n",
            "4                   0.0           1.0     1.0  ...            1.0   \n",
            "\n",
            "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
            "0          0.0      5.0      18.0      15.0       1.0  0.0   9.0        4.0   \n",
            "1          1.0      3.0       0.0       0.0       0.0  0.0   7.0        6.0   \n",
            "2          1.0      5.0      30.0      30.0       1.0  0.0   9.0        4.0   \n",
            "3          0.0      2.0       0.0       0.0       0.0  0.0  11.0        3.0   \n",
            "4          0.0      2.0       3.0       0.0       0.0  0.0  11.0        5.0   \n",
            "\n",
            "   Income  \n",
            "0     3.0  \n",
            "1     1.0  \n",
            "2     8.0  \n",
            "3     6.0  \n",
            "4     4.0  \n",
            "\n",
            "[5 rows x 22 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop('Diabetes_012', axis=1)\n",
        "y = data['Diabetes_012']\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into train, validation, and test sets (70% train, 15% val, 15% test)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_normalized, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "# Display shapes of the datasets\n",
        "X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nx44ylQWSL9",
        "outputId": "594350c7-4fc1-4828-f117-7a12f811ddac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((177576, 21), (38052, 21), (38052, 21), (177576,), (38052,), (38052,))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Convert datasets to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
        "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val.values, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "# Create DataLoader objects\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize hidden state\n",
        "        # Reshape the input to have a sequence length dimension, even if it's 1\n",
        "        x = x.unsqueeze(1)  # Add a dimension for sequence length\n",
        "        h0 = torch.zeros(self.rnn.num_layers, x.size(0), self.rnn.hidden_size).to(x.device)\n",
        "\n",
        "        # RNN forward pass\n",
        "        out, _ = self.rnn(x, h0)\n",
        "\n",
        "        # Take the output of the last time step\n",
        "        out = out[:, -1, :]\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "UwxyxR5iWZ-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training and evaluation functions\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
        "    model.to(device)\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in val_loader:\n",
        "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "                outputs = model(X_batch)\n",
        "                loss = criterion(outputs, y_batch)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += y_batch.size(0)\n",
        "                correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {running_loss/len(train_loader):.4f}, \"\n",
        "              f\"Val Loss: {val_loss/len(val_loader):.4f}, Val Accuracy: {100 * correct/total:.2f}%\")\n",
        "\n",
        "    # Return validation accuracy and loss\n",
        "    val_accuracy = 100 * correct / total\n",
        "    val_loss = val_loss / len(val_loader)\n",
        "    return val_accuracy, val_loss # Added this line to return the values"
      ],
      "metadata": {
        "id": "_YBK9emfWi8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model parameters\n",
        "input_size = X_train.shape[1]\n",
        "hidden_size = 32\n",
        "num_layers = 1\n",
        "num_classes = len(y.unique())\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = RNNModel(input_size, hidden_size, num_layers, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otlTEx-1Wg3L",
        "outputId": "62b52759-c76d-40bb-e77e-dfe2a2276f51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Train Loss: 0.4156, Val Loss: 0.3971, Val Accuracy: 84.88%\n",
            "Epoch [2/5], Train Loss: 0.3964, Val Loss: 0.3939, Val Accuracy: 84.99%\n",
            "Epoch [3/5], Train Loss: 0.3947, Val Loss: 0.3939, Val Accuracy: 84.91%\n",
            "Epoch [4/5], Train Loss: 0.3942, Val Loss: 0.3925, Val Accuracy: 84.97%\n",
            "Epoch [5/5], Train Loss: 0.3937, Val Loss: 0.3919, Val Accuracy: 85.03%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(85.02838221381268, 0.3918576860878648)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_sizes = [32, 64, 128]\n",
        "results = {}\n",
        "for hidden_size in hidden_sizes:\n",
        "    model = RNNModel(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    val_accuracy, val_loss = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5, device=device)  # Train for 5 epochs for each hidden size\n",
        "    results[hidden_size] = {'accuracy': val_accuracy, 'loss': val_loss}\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csdZdDIyaqHy",
        "outputId": "9e22bcfa-937e-4c2d-bec1-0465e0ec6afb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Train Loss: 0.4143, Val Loss: 0.3974, Val Accuracy: 84.84%\n",
            "Epoch [2/5], Train Loss: 0.3960, Val Loss: 0.3948, Val Accuracy: 84.96%\n",
            "Epoch [3/5], Train Loss: 0.3947, Val Loss: 0.3934, Val Accuracy: 84.91%\n",
            "Epoch [4/5], Train Loss: 0.3940, Val Loss: 0.3937, Val Accuracy: 85.02%\n",
            "Epoch [5/5], Train Loss: 0.3935, Val Loss: 0.3947, Val Accuracy: 84.86%\n",
            "Epoch [1/5], Train Loss: 0.4122, Val Loss: 0.3948, Val Accuracy: 85.00%\n",
            "Epoch [2/5], Train Loss: 0.3964, Val Loss: 0.3951, Val Accuracy: 84.94%\n",
            "Epoch [3/5], Train Loss: 0.3947, Val Loss: 0.3925, Val Accuracy: 84.98%\n",
            "Epoch [4/5], Train Loss: 0.3942, Val Loss: 0.3921, Val Accuracy: 85.04%\n",
            "Epoch [5/5], Train Loss: 0.3937, Val Loss: 0.3936, Val Accuracy: 85.04%\n",
            "Epoch [1/5], Train Loss: 0.4078, Val Loss: 0.3975, Val Accuracy: 84.85%\n",
            "Epoch [2/5], Train Loss: 0.3975, Val Loss: 0.3946, Val Accuracy: 84.87%\n",
            "Epoch [3/5], Train Loss: 0.3958, Val Loss: 0.3957, Val Accuracy: 84.91%\n",
            "Epoch [4/5], Train Loss: 0.3951, Val Loss: 0.3938, Val Accuracy: 84.93%\n",
            "Epoch [5/5], Train Loss: 0.3944, Val Loss: 0.3935, Val Accuracy: 84.97%\n",
            "{32: {'accuracy': 84.8628192999054, 'loss': 0.39467904727999903}, 64: {'accuracy': 85.03889414485441, 'loss': 0.3936374429394217}, 128: {'accuracy': 84.96531062756229, 'loss': 0.39348481097141236}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizers = [optim.SGD(model.parameters(), lr=0.001), optim.RMSprop(model.parameters(), lr=0.001), optim.Adam(model.parameters(), lr=0.001)]\n",
        "optimizer_names = ['SGD', 'RMSprop', 'Adam']\n",
        "results = {}\n",
        "for optimizer, optimizer_name in zip(optimizers, optimizer_names):\n",
        "    model = RNNModel(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "    val_accuracy, val_loss = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5, device=device)\n",
        "    results[optimizer_name] = {'accuracy': val_accuracy, 'loss': val_loss}\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "id": "bxgk2DPeauar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99da1a6d-8eb2-4a85-b9cd-4e38dc2a69d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Train Loss: 1.0626, Val Loss: 1.0627, Val Accuracy: 48.24%\n",
            "Epoch [2/5], Train Loss: 1.0626, Val Loss: 1.0627, Val Accuracy: 48.24%\n",
            "Epoch [3/5], Train Loss: 1.0626, Val Loss: 1.0627, Val Accuracy: 48.24%\n",
            "Epoch [4/5], Train Loss: 1.0626, Val Loss: 1.0627, Val Accuracy: 48.24%\n",
            "Epoch [5/5], Train Loss: 1.0626, Val Loss: 1.0627, Val Accuracy: 48.24%\n",
            "Epoch [1/5], Train Loss: 1.0908, Val Loss: 1.0898, Val Accuracy: 37.20%\n",
            "Epoch [2/5], Train Loss: 1.0908, Val Loss: 1.0898, Val Accuracy: 37.20%\n",
            "Epoch [3/5], Train Loss: 1.0908, Val Loss: 1.0898, Val Accuracy: 37.20%\n",
            "Epoch [4/5], Train Loss: 1.0908, Val Loss: 1.0898, Val Accuracy: 37.20%\n",
            "Epoch [5/5], Train Loss: 1.0908, Val Loss: 1.0898, Val Accuracy: 37.20%\n",
            "Epoch [1/5], Train Loss: 1.0545, Val Loss: 1.0550, Val Accuracy: 54.90%\n",
            "Epoch [2/5], Train Loss: 1.0545, Val Loss: 1.0550, Val Accuracy: 54.90%\n",
            "Epoch [3/5], Train Loss: 1.0545, Val Loss: 1.0550, Val Accuracy: 54.90%\n",
            "Epoch [4/5], Train Loss: 1.0545, Val Loss: 1.0550, Val Accuracy: 54.90%\n",
            "Epoch [5/5], Train Loss: 1.0545, Val Loss: 1.0550, Val Accuracy: 54.90%\n",
            "{'SGD': {'accuracy': 48.23925155050983, 'loss': 1.0626525468185168}, 'RMSprop': {'accuracy': 37.20435193945128, 'loss': 1.089820087857607}, 'Adam': {'accuracy': 54.90381583096815, 'loss': 1.0549805412773325}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# ... (model initialization and other setup) ...\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3)  # Reduce LR if val loss plateaus\n",
        "best_val_loss = float('inf')\n",
        "patience = 5  # Number of epochs to wait for improvement\n",
        "epochs_without_improvement = 0\n",
        "\n",
        "for epoch in range(350):  # Max epochs\n",
        "    # ... (training loop) ...\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            val_loss += loss.item()\n",
        "    val_loss /= len(val_loader) # Calculate average validation loss\n",
        "\n",
        "    scheduler.step(val_loss)  # Update learning rate\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        epochs_without_improvement = 0\n",
        "    else:\n",
        "        epochs_without_improvement += 1\n",
        "        if epochs_without_improvement >= patience:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break"
      ],
      "metadata": {
        "id": "Taj8EsXra0S2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3acc60a1-4c39-4840-e1c3-fd9cd176627b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping triggered\n"
          ]
        }
      ]
    }
  ]
}