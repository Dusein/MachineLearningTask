{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyND6h0qoy3Qv6494oN8UBXJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dusein/MachineLearningTask/blob/main/14thWeekTask/Bidirectional_RNN_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfaQzLJAoNme"
      },
      "outputs": [],
      "source": [
        "# Import Libraries and Load Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ganti 'your_file_path' dengan path sebenarnya ke file CSV Anda di Google Drive\n",
        "file_path = '/content/sample_data/diabetes_012_health_indicators_BRFSS2015.csv'\n",
        "\n",
        "# Membaca file CSV ke dalam DataFrame\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Menampilkan beberapa baris pertama dari DataFrame\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "OME5OxFToTnH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a25219dc-6d99-4b98-c91b-9a8dcb4b4362"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Diabetes_012  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
            "0           0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
            "1           0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
            "2           0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
            "3           0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
            "4           0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
            "\n",
            "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
            "0                   0.0           0.0     0.0  ...            1.0   \n",
            "1                   0.0           1.0     0.0  ...            0.0   \n",
            "2                   0.0           0.0     1.0  ...            1.0   \n",
            "3                   0.0           1.0     1.0  ...            1.0   \n",
            "4                   0.0           1.0     1.0  ...            1.0   \n",
            "\n",
            "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
            "0          0.0      5.0      18.0      15.0       1.0  0.0   9.0        4.0   \n",
            "1          1.0      3.0       0.0       0.0       0.0  0.0   7.0        6.0   \n",
            "2          1.0      5.0      30.0      30.0       1.0  0.0   9.0        4.0   \n",
            "3          0.0      2.0       0.0       0.0       0.0  0.0  11.0        3.0   \n",
            "4          0.0      2.0       3.0       0.0       0.0  0.0  11.0        5.0   \n",
            "\n",
            "   Income  \n",
            "0     3.0  \n",
            "1     1.0  \n",
            "2     8.0  \n",
            "3     6.0  \n",
            "4     4.0  \n",
            "\n",
            "[5 rows x 22 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "CZdu_gA4qQPn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pisahkan fitur dan label\n",
        "X = data.iloc[:, 1:].values\n",
        "y = data.iloc[:, 0].values\n",
        "\n",
        "# Standarisasi data\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split dataset menjadi training dan testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert data ke Tensor\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# DataLoader untuk batch training\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "bfRmIa43qM8Y"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BiRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
        "        super(BiRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_size * 2, output_size)  # *2 karena bidirectional\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Inisialisasi hidden state\n",
        "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        out = out[:, -1, :]  # Ambil output terakhir\n",
        "        out = self.fc(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "NXli-6B0qS3y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs, early_stopping_patience=10):\n",
        "    best_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            # Tambahkan dimensi baru untuk sequence_length\n",
        "            X_batch, y_batch = X_batch.unsqueeze(1).to(device), y_batch.to(device)  # [batch_size, 1, input_size]\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # Evaluasi pada validation set\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in val_loader:\n",
        "                # Tambahkan dimensi baru untuk sequence_length\n",
        "                X_batch, y_batch = X_batch.unsqueeze(1).to(device), y_batch.to(device)\n",
        "                outputs = model(X_batch)\n",
        "                loss = criterion(outputs, y_batch)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "        # Early stopping\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= early_stopping_patience:\n",
        "                print(\"Early stopping triggered\")\n",
        "                break\n"
      ],
      "metadata": {
        "id": "TiAd2xNsqUKF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = X_train.shape[1]  # Jumlah fitur (input size)\n",
        "output_size = len(np.unique(y_train))  # Jumlah kelas (output size)\n",
        "\n",
        "hidden_sizes = [16, 32, 64]\n",
        "results_hidden_size = {}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "for hidden_size in hidden_sizes:\n",
        "    print(f\"Training with Hidden Size: {hidden_size}\")\n",
        "    model = BiRNN(input_size=input_size, hidden_size=hidden_size, output_size=output_size).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Train model\n",
        "    train_model(model, criterion, optimizer, train_loader, test_loader, num_epochs=10)\n",
        "    results_hidden_size[hidden_size] = model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCJqP1PhqWJD",
        "outputId": "55111183-2912-4af3-dd37-48525d909727"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with Hidden Size: 16\n",
            "Epoch 1/10, Train Loss: 0.4079, Val Loss: 0.3939\n",
            "Epoch 2/10, Train Loss: 0.3957, Val Loss: 0.3922\n",
            "Epoch 3/10, Train Loss: 0.3948, Val Loss: 0.3911\n",
            "Epoch 4/10, Train Loss: 0.3943, Val Loss: 0.3910\n",
            "Epoch 5/10, Train Loss: 0.3939, Val Loss: 0.3908\n",
            "Epoch 6/10, Train Loss: 0.3936, Val Loss: 0.3932\n",
            "Epoch 7/10, Train Loss: 0.3934, Val Loss: 0.3913\n",
            "Epoch 8/10, Train Loss: 0.3931, Val Loss: 0.3911\n",
            "Epoch 9/10, Train Loss: 0.3929, Val Loss: 0.3910\n",
            "Epoch 10/10, Train Loss: 0.3927, Val Loss: 0.3924\n",
            "Training with Hidden Size: 32\n",
            "Epoch 1/10, Train Loss: 0.4048, Val Loss: 0.3955\n",
            "Epoch 2/10, Train Loss: 0.3967, Val Loss: 0.3922\n",
            "Epoch 3/10, Train Loss: 0.3955, Val Loss: 0.3912\n",
            "Epoch 4/10, Train Loss: 0.3949, Val Loss: 0.3923\n",
            "Epoch 5/10, Train Loss: 0.3943, Val Loss: 0.3933\n",
            "Epoch 6/10, Train Loss: 0.3940, Val Loss: 0.3915\n",
            "Epoch 7/10, Train Loss: 0.3937, Val Loss: 0.3918\n",
            "Epoch 8/10, Train Loss: 0.3935, Val Loss: 0.3948\n",
            "Epoch 9/10, Train Loss: 0.3933, Val Loss: 0.3914\n",
            "Epoch 10/10, Train Loss: 0.3930, Val Loss: 0.3922\n",
            "Training with Hidden Size: 64\n",
            "Epoch 1/10, Train Loss: 0.4051, Val Loss: 0.3946\n",
            "Epoch 2/10, Train Loss: 0.3971, Val Loss: 0.3929\n",
            "Epoch 3/10, Train Loss: 0.3960, Val Loss: 0.3921\n",
            "Epoch 4/10, Train Loss: 0.3953, Val Loss: 0.3948\n",
            "Epoch 5/10, Train Loss: 0.3947, Val Loss: 0.3911\n",
            "Epoch 6/10, Train Loss: 0.3942, Val Loss: 0.3918\n",
            "Epoch 7/10, Train Loss: 0.3942, Val Loss: 0.3917\n",
            "Epoch 8/10, Train Loss: 0.3940, Val Loss: 0.3919\n",
            "Epoch 9/10, Train Loss: 0.3937, Val Loss: 0.3935\n",
            "Epoch 10/10, Train Loss: 0.3934, Val Loss: 0.3917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BiRNNWithPooling(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, pooling=\"max\", num_layers=1):\n",
        "        super(BiRNNWithPooling, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_size * 2, output_size)  # *2 karena bidirectional\n",
        "        self.pooling = pooling\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.rnn(x, h0)\n",
        "\n",
        "        if self.pooling == \"max\":\n",
        "            out, _ = torch.max(out, dim=1)\n",
        "        elif self.pooling == \"avg\":\n",
        "            out = torch.mean(out, dim=1)\n",
        "\n",
        "        out = self.fc(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "91QcwCVZqYiQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizers = {\n",
        "    \"SGD\": torch.optim.SGD,\n",
        "    \"RMSProp\": torch.optim.RMSprop,\n",
        "    \"Adam\": torch.optim.Adam,\n",
        "}\n",
        "\n",
        "for opt_name, opt_func in optimizers.items():\n",
        "    print(f\"Training with Optimizer: {opt_name}\")\n",
        "    model = BiRNN(input_size=input_size, hidden_size=32, output_size=output_size).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = opt_func(model.parameters(), lr=0.001)\n",
        "\n",
        "    train_model(model, criterion, optimizer, train_loader, test_loader, num_epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8p6wtFEtqaVi",
        "outputId": "d3622be3-cea3-4068-af02-21c8d860402f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with Optimizer: SGD\n",
            "Epoch 1/10, Train Loss: 0.5030, Val Loss: 0.4095\n",
            "Epoch 2/10, Train Loss: 0.4069, Val Loss: 0.4008\n",
            "Epoch 3/10, Train Loss: 0.4029, Val Loss: 0.3991\n",
            "Epoch 4/10, Train Loss: 0.4018, Val Loss: 0.3985\n",
            "Epoch 5/10, Train Loss: 0.4012, Val Loss: 0.3981\n",
            "Epoch 6/10, Train Loss: 0.4008, Val Loss: 0.3978\n",
            "Epoch 7/10, Train Loss: 0.4005, Val Loss: 0.3975\n",
            "Epoch 8/10, Train Loss: 0.4003, Val Loss: 0.3973\n",
            "Epoch 9/10, Train Loss: 0.4000, Val Loss: 0.3971\n",
            "Epoch 10/10, Train Loss: 0.3998, Val Loss: 0.3970\n",
            "Training with Optimizer: RMSProp\n",
            "Epoch 1/10, Train Loss: 0.4018, Val Loss: 0.3956\n",
            "Epoch 2/10, Train Loss: 0.3965, Val Loss: 0.3923\n",
            "Epoch 3/10, Train Loss: 0.3952, Val Loss: 0.3920\n",
            "Epoch 4/10, Train Loss: 0.3948, Val Loss: 0.3948\n",
            "Epoch 5/10, Train Loss: 0.3946, Val Loss: 0.3935\n",
            "Epoch 6/10, Train Loss: 0.3941, Val Loss: 0.3909\n",
            "Epoch 7/10, Train Loss: 0.3939, Val Loss: 0.3914\n",
            "Epoch 8/10, Train Loss: 0.3937, Val Loss: 0.3922\n",
            "Epoch 9/10, Train Loss: 0.3936, Val Loss: 0.3910\n",
            "Epoch 10/10, Train Loss: 0.3934, Val Loss: 0.3913\n",
            "Training with Optimizer: Adam\n",
            "Epoch 1/10, Train Loss: 0.4041, Val Loss: 0.3944\n",
            "Epoch 2/10, Train Loss: 0.3961, Val Loss: 0.3920\n",
            "Epoch 3/10, Train Loss: 0.3949, Val Loss: 0.3929\n",
            "Epoch 4/10, Train Loss: 0.3946, Val Loss: 0.3904\n",
            "Epoch 5/10, Train Loss: 0.3940, Val Loss: 0.3910\n",
            "Epoch 6/10, Train Loss: 0.3938, Val Loss: 0.3908\n",
            "Epoch 7/10, Train Loss: 0.3936, Val Loss: 0.3915\n",
            "Epoch 8/10, Train Loss: 0.3935, Val Loss: 0.3903\n",
            "Epoch 9/10, Train Loss: 0.3931, Val Loss: 0.3929\n",
            "Epoch 10/10, Train Loss: 0.3930, Val Loss: 0.3910\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = [5, 50]\n",
        "\n",
        "for num_epochs in epochs:\n",
        "    print(f\"Training with Epochs: {num_epochs}\")\n",
        "    model = BiRNN(input_size=input_size, hidden_size=32, output_size=output_size).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    train_model(model, criterion, optimizer, train_loader, test_loader, num_epochs=num_epochs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CACeRgQmqbyu",
        "outputId": "d94a5819-dfa6-43a1-c7ce-703f6c139e8e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with Epochs: 5\n",
            "Epoch 1/5, Train Loss: 0.4044, Val Loss: 0.3939\n",
            "Epoch 2/5, Train Loss: 0.3963, Val Loss: 0.3951\n",
            "Epoch 3/5, Train Loss: 0.3953, Val Loss: 0.3920\n",
            "Epoch 4/5, Train Loss: 0.3946, Val Loss: 0.3936\n",
            "Epoch 5/5, Train Loss: 0.3944, Val Loss: 0.3916\n",
            "Training with Epochs: 50\n",
            "Epoch 1/50, Train Loss: 0.4054, Val Loss: 0.3950\n",
            "Epoch 2/50, Train Loss: 0.3962, Val Loss: 0.3941\n",
            "Epoch 3/50, Train Loss: 0.3953, Val Loss: 0.3927\n",
            "Epoch 4/50, Train Loss: 0.3948, Val Loss: 0.3911\n",
            "Epoch 5/50, Train Loss: 0.3943, Val Loss: 0.3916\n",
            "Epoch 6/50, Train Loss: 0.3938, Val Loss: 0.3916\n",
            "Epoch 7/50, Train Loss: 0.3937, Val Loss: 0.3900\n",
            "Epoch 8/50, Train Loss: 0.3935, Val Loss: 0.3921\n",
            "Epoch 9/50, Train Loss: 0.3932, Val Loss: 0.3914\n",
            "Epoch 10/50, Train Loss: 0.3932, Val Loss: 0.3906\n",
            "Epoch 11/50, Train Loss: 0.3929, Val Loss: 0.3928\n",
            "Epoch 12/50, Train Loss: 0.3927, Val Loss: 0.3940\n",
            "Epoch 13/50, Train Loss: 0.3927, Val Loss: 0.3910\n",
            "Epoch 14/50, Train Loss: 0.3924, Val Loss: 0.3916\n",
            "Epoch 15/50, Train Loss: 0.3923, Val Loss: 0.3926\n",
            "Epoch 16/50, Train Loss: 0.3921, Val Loss: 0.3946\n",
            "Epoch 17/50, Train Loss: 0.3921, Val Loss: 0.3914\n",
            "Early stopping triggered\n"
          ]
        }
      ]
    }
  ]
}